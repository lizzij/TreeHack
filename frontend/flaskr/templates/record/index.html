{% extends 'base.html' %}

{% block header %}
<script src="https://unpkg.com/houndify@3.0.3/dist/houndify.js"></script>
<!-- This is the houndify css-->
<link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.2.4/semantic.min.css"
/>

<h1>{% block title %}{% endblock %}</h1>
{% endblock %}

{% block content %}
  <div id="conversationContainer">
    <div class="speech-bubble-left"><p>Hello! Tell me what you want to do: "Start my therapy" or "Start my exercises"</p></div>
    <div class="speech-bubble-right" id="firstResponse" style="visibility:hidden;"><p></p></div>
    <div class="speech-bubble-left" id="secondResponse" style="visibility:hidden;"><p></p></div>
    
    <div id="choicesContainer">
      <input class="choices" type="button" id="mixBut" value="Start" style="visibility:hidden;" />
    </div>
  </div>
  
  <div class="loader" style="display:none" id="processing_loader"></div>
	<div id="voiceInputContainer">
		<div class="ui center aligned basic segment container" id="voiceInput">

	      <form id="form" class="ui form" action="javascript:void(0);">

	        <div class="ui action big labeled fluid input field">
	          <div class="ui icon basic label button" onclick="onMicrophoneClick()">
	            <i id="voiceIcon" class="unmute big icon"></i>
	          </div>
	          <input
	            id="query"
	            type="text"
	            placeholder="Say something..."
	          />
	          <button
	            id="textSearchButton"
	            class="ui icon button"
	            onclick="initTextRequest()"
	          >
	            <i class="search big icon"></i>
	          </button>
	        </div>

	        <!-- <div class="ui field">
	          <label class="ui label" for="file"
	            >Or upload a recorded voice query from a file</label
	          >
	          <input type="file" id="file" name="file" onchange="onFileUpload()" />
	        </div> -->

	        <div id="status" class="ui info message">
	          Click on microphone icon or type in the text query.
	        </div>

	        <div class="ui field" hidden>
	          <label>Response object</label>
	          <textarea id="responseJSON"></textarea>
	        </div>
	        <div class="ui field" hidden>
	          <label>Search info object</label>
	          <textarea id="infoJSON"></textarea>
	        </div>
	      </form>
	    </div>
	</div>

  <script src="https://unpkg.com/synth-js/dst/synth.min.js"></script>
  <script>
    // Start of Houndify code

    function textToSpeech(phrase) {
      window.speechSynthesis.cancel();
      // list of languages is probably not loaded, wait for it
      if(window.speechSynthesis.getVoices().length == 0) {
        window.speechSynthesis.addEventListener('voiceschanged', function() {
          textToSpeechHelper(phrase);
        });
      }
      else {
        // languages list available, no need to wait
        textToSpeechHelper(phrase);
      }

    }

    function textToSpeechHelper(phrase) {
      // get all voices that browser offers
      var available_voices = window.speechSynthesis.getVoices();
      console.log(available_voices);
      // this will hold an english voice
      var english_voice = '';

      // find voice by language locale "en-US"
      // if not then select the first voice
      /* We want uk female!
      for(var i=0; i<available_voices.length; i++) {
        if(available_voices[i].lang === 'en-US') {
          english_voice = available_voices[i];
          break;
        }
      }
      */
     english_voice = available_voices[4];
      if(english_voice === '')
        english_voice = available_voices[0];

      // new SpeechSynthesisUtterance object
      var utter = new SpeechSynthesisUtterance();
      utter.rate = 0.75;
      utter.pitch = 1;
      utter.text = phrase;
      utter.voice = english_voice;

      // event after text has been spoken
      utter.onend = function() {
        console.log('Speech has finished');
        window.speechSynthesis.cancel();
      }

      // speak
      window.speechSynthesis.speak(utter);
    }

    //HTML ELEMENTS FOR DISPLAYING RESPONSE AND INFO JSON's
    var responseElt = document.getElementById("responseJSON");
    var infoElt = document.getElementById("infoJSON");
    var statusElt = document.getElementById("status");
    var transcriptElt = document.getElementById("query");

    var clientID = "6gG_SPtR_YNCOaTvI0IK5w==";
    var conversationState = null;
    var voiceRequest = null;

    var recorder = new Houndify.AudioRecorder();
    recorder.on("start", function() {
      //Initialize VoiceRequest
      voiceRequest = initVoiceRequest(recorder.sampleRate);
      document.getElementById("voiceIcon").className =
      "selected radio icon big red";
    });

    recorder.on("data", function(data) {
      voiceRequest.write(data);
    });

    recorder.on("end", function() {
      voiceRequest.end();
      statusElt.innerText = "Stopped recording. Waiting for response...";
      document.getElementById("voiceIcon").className = "unmute big icon";
      document.getElementById("textSearchButton").disabled = false;
      document.getElementById("query").readOnly = false;
    });

    recorder.on("error", function(error) {
      voiceRequest.abort();
      statusElt.innerText = "Error: " + error;
      document.getElementById("voiceIcon").className = "unmute big icon";
      document.getElementById("textSearchButton").disabled = false;
      document.getElementById("query").readOnly = false;
    });

    function initTextRequest() {
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = true;

      var queryString = document.getElementById("query").value;
      statusElt.innerText = "Sending text request...";
      fetch('/textSearchProxy?query=' + encodeURIComponent(queryString))
      .then(
        function(response) {
          if (response.status !== 200) {
            console.log('Looks like there was a problem. Status Code: ' +
              response.status);
            return;
          }
          // Examine the text in the response
          response.json().then(function(data) {
            console.log(data);
            onResponse(data, {});
          });
        }
      )
      .catch(function(err) {
        console.log('Fetch Error :-S', err);
        onError(data, {});
      });
      //Initialize TextRequest
      /*
      var textRequest = new Houndify.TextRequest({
        //Text query
        query: queryString,

        //Your Houndify Client ID
        clientId: clientID,

        //For testing environment you might want to authenticate on frontend without Node.js server.
        //In that case you may pass in your Houndify Client Key instead of "authURL".
        clientKey: "3lHbv1T8X5UDUa4tGhogToKa9iBIAMLdGK02zUq-ZwsBZ6BdaAElh42Z-nVnDoKfiu_3zCYxqrL4Ux2Iqs7X9A==",

        //Otherwise you need to create an endpoint on your server
        //for handling the authentication.
        //See SDK's server-side method HoundifyExpress.createAuthenticationHandler().
        //authURL: "/houndifyAuth",

        //REQUEST INFO JSON
        //See https://houndify.com/reference/RequestInfo
        requestInfo: {
          UserID: "test_user",
          Latitude: 37.388309,
          Longitude: -121.973968,
        },

        //Pass the current ConversationState stored from previous queries
        //See https://www.houndify.com/docs#conversation-state
        conversationState: conversationState,

        //You need to create an endpoint on your server
        //for handling the authentication and proxying
        //text search http requests to Houndify backend
        //See SDK's server-side method HoundifyExpress.createTextProxyHandler().
        proxy: {
          method: "POST",
          url: "/textSearchProxy",
          // headers: {}
          // ... More proxy options will be added as needed
        },

        //Response and error handlers
        onResponse: onResponse,
        onError: onError,
      });
      */
    }

    function initVoiceRequest(sampleRate) {
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = true;

      var voiceRequest = new Houndify.VoiceRequest({
      //Your Houndify Client ID
      clientId: clientID,
      clientKey: "3lHbv1T8X5UDUa4tGhogToKa9iBIAMLdGK02zUq-ZwsBZ6BdaAElh42Z-nVnDoKfiu_3zCYxqrL4Ux2Iqs7X9A==",
      //authURL: "/houndifyAuth",
      requestInfo: {
        UserID: "test_user",
        Latitude: 37.388309,
        Longitude: -121.973968,
      },
      conversationState,

      //Sample rate of input audio
      sampleRate,

      //Enable Voice Activity Detection
      //Default: true
      enableVAD: true,

      //Partial transcript, response and error handlers
      onTranscriptionUpdate: onTranscriptionUpdate,
      onResponse: function(response, info) {
        recorder.stop();
        onResponse(response, info);
      },
      onError: function(err, info) {
        recorder.stop();
        onError(err, info);
      },
      });

      return voiceRequest;
    }

    function onMicrophoneClick() {
      if (recorder && recorder.isRecording()) {
      recorder.stop();
      return;
      }

      recorder.start();

      statusElt.innerText = "Streaming voice request...";
      document.getElementById("voiceIcon").className =
      "loading circle notched icon big";
      document.getElementById("textSearchButton").disabled = true;
      document.getElementById("query").readOnly = true;
    }

    function onFileUpload() {
      var reader = new FileReader();
      reader.onload = function() {
      //In browsers only you can also upload and decode
      //audio file using decodeArrayBuffer() method
      //Stream 8/16 kHz mono 16-bit little-endian PCM samples
      //in Int16Array() chunks to backend
      var arrayBuffer = reader.result;
      Houndify.decodeAudioData(arrayBuffer, function(err, result) {
        statusElt.innerText = "Streaming audio from file...";
        voiceRequest = initVoiceRequest(result.sampleRate);
        voiceRequest.write(result.audioData);
        voiceRequest.end();
      });

      statusElt.innerText = "Decoding audio from file...";
      };

      var file = document.getElementById("file").files[0];
      reader.readAsArrayBuffer(file);
    }

		function chooseText() {
			var arr = [
        'my grandfather you asked to know all about how he is nearly ninety three years old',
        'the things they asked about were whether the judge should be the one that does the sentencing',
        'the rain in spain falls mainly on the plain'
      ];
			return arr[Math.floor(Math.random() * arr.length)];
		}

    function startSession() {
  		var mixBut = document.getElementById("mixBut");

      mixBut.style.visibility = "visible";
  		mixBut.addEventListener("click", Start);

  		function Start() {
  			console.log("Started");
  			mixBut.removeEventListener("click", Start);
  			mixBut.addEventListener("click", Stop);
  			mixBut.value = "Stop";
  			navigator.mediaDevices.getUserMedia({
  				audio: true,
  				video: false
  			}).then(handleSuccess);
  		}

  		function Stop() {
  			console.log("Stopped");
  			mixBut.removeEventListener("click", Stop);
        // mixBut.addEventListener("click", ToEval);
  			mixBut.value = "Evaluating";
  			// function ToEval() {
  			//  	console.log("Evaluate");
  			//  	//window.location.href='/score';
  			//  }
  		}

  		var handleSuccess = function(stream) {
  			var context = new AudioContext();
  			var source = context.createMediaStreamSource(stream);
  			var processor = context.createScriptProcessor(1024, 1, 1);
  			var data = [];

  			source.connect(processor);
  			processor.connect(context.destination);

  			processor.onaudioprocess = function(e) {
  				data.push.apply(data, e.inputBuffer.getChannelData(0));
  				// cut off after 5 seconds
  				if (mixBut.value == "Evaluating") {
  					context.close();
  					var track = stream.getAudioTracks()[0];
  					track.stop();
  					// Convert this to WAV
  					var wav = new synth.WAV(1, context.sampleRate, 16, true, data);
  					var blob = wav.toBlob();

            // TODO
            var xhr=new XMLHttpRequest();
            xhr.onload=function(e) {
                if(this.readyState === 4) {
                    console.log("Server returned: ",e.target.responseText);
                    response = JSON.stringify(JSON.parse(e.target.responseText));
  			          	window.location.href='/score/' + response;
                }
            };
            var fd = new FormData();
            fd.append("wav_file", blob, "filename.wav");
            fd.append("target_sentence", secondResponse.innerText.slice(5));
            xhr.open("POST","/process_audio",true);
            
            var processLoader = document.getElementById("processing_loader");
            processLoader.style.display = "";
            mixBut.style.display = "none";
            xhr.send(fd);
            /*
            var data = new FormData()
            data.append('wav_file', blob);
            data.append('target_sentence', secondResponse.innerText.slice(5))

            fetch('/process_audio', {
              method: 'POST',
              body: data
            });
            */
  					// let request = new XMLHttpRequest();
  					// request.open("POST", 'some_url/', true);
  					// request.send(data)
  					// do something with blob

  					var src = URL.createObjectURL(blob);
  					var audio = new Audio();
  					audio.controls = true;
  					document.body.appendChild(audio);
  					// play back audio
  					audio.addEventListener('canplaythrough', function() {
  						audio.play();
  					});
  					audio.src = src;
  				}
  			};
  		};
    }

    //Fires after server responds with Response JSON
    //Info object contains useful information about the completed request
    //See https://houndify.com/reference/HoundServer
    function onResponse(response, info) {
      if (response.AllResults && response.AllResults.length) {
      //Pick and store appropriate ConversationState from the results.
      //This example takes the default one from the first result.
      conversationState = response.AllResults[0].ConversationState;
      }

      statusElt.innerText = "Received response.";
      //responseElt.parentNode.hidden = false;
      //responseElt.value = JSON.stringify(response, undefined, 2);

      let action = (response.AllResults[0].Result || {}).action;
      if (action === undefined) {
        // errored
      } else if (action == "greeting") {
				console.log(action);
				var firstResponse = document.getElementById("firstResponse");
				firstResponse.style.visibility='visible'
				var transcript = response.Disambiguation.ChoiceData[0].FormattedTranscription;
        console.log(transcript);
				firstResponse.innerText = transcript;

				var secondResponse = document.getElementById("secondResponse");
				secondResponse.style.visibility='visible';
        secondResponse.innerText = response.AllResults[0].SpokenResponse;
        textToSpeech(response.AllResults[0].SpokenResponse);

      } else if (action == "start_session") {

				// expected vs actual test
				console.log(action);
				var firstResponse = document.getElementById("firstResponse");
				firstResponse.style.visibility='visible'
				var transcript = response.Disambiguation.ChoiceData[0].FormattedTranscription;
				console.log(transcript)
				firstResponse.innerText = transcript;

				var secondResponse = document.getElementById("secondResponse");
				secondResponse.style.visibility='visible';
				var actualText = chooseText();
        secondResponse.innerText = 'Say: ' + actualText;
        
        textToSpeech(secondResponse.innerText);

        // TODO send the actualText and encoded wva, get back score
        startSession();

			} else if (action == "start_exercises") {

				// start face movement exercises
				console.log(action);
        textToSpeech("Alright, starting your exercises!");
        setTimeout(function(){
          window.location.href='{{ url_for('practice.start_practice') }}';
        }, 3000);

			} else if (action == "restart_session") {

				console.log(action);
        textToSpeech("Sounds good, restarting your session.");
        
        setTimeout(function(){
				  window.location.href='{{ url_for('record.index') }}';
        }, 3000);
			}

      //infoElt.parentNode.hidden = false;
      //infoElt.value = JSON.stringify(info, undefined, 2);
    }

    /*
    // Example of success
    {
      "Format": "SoundHoundVoiceSearchResult",
      "FormatVersion": "1.0",
      "Status": "OK",
      "NumToReturn": 1,
      "AllResults": [
        {
          "CommandKind": "ClientMatchCommand",
          "SpokenResponse": "Sounds gucci to me!",
          "SpokenResponseLong": "Sounds gucci to me!",
          "WrittenResponse": "Sounds gucci to me!",
          "WrittenResponseLong": "Sounds gucci to me!",
          "AutoListen": false,
          "ViewType": [
            "Native",
            "None"
          ],
          "Result": {
            "action": "greeting"
          }
        }
      ],
      "Disambiguation": {
        "NumToShow": 1,
        "ChoiceData": [
          {
            "Transcription": "ten to the at terminal two",
            "ConfidenceScore": 0.6859999999999999,
            "FormattedTranscription": "ten to the at terminal two",
            "FixedTranscription": ""
          }
        ]
      }
    }
    // Example of failure
    {
      "Format": "SoundHoundVoiceSearchResult",
      "FormatVersion": "1.0",
      "Status": "OK",
      "NumToReturn": 1,
      "AllResults": [
        {
          "CommandKind": "NoResultCommand",
          "SpokenResponse": "",
          "SpokenResponseLong": "Didn't get that!",
          "WrittenResponse": "Didn't get that!",
          "WrittenResponseLong": "Didn't get that!",
          "AutoListen": false,
          "ViewType": [
            "Native",
            "None"
          ],
          "TranscriptionSearchURL": "http://www.google.com/#q=ten%20to%20the%20at%20terminal%20two"
        }
      ],
      "Disambiguation": {
        "NumToShow": 1,
        "ChoiceData": [
          {
            "Transcription": "ten to the at terminal two",
            "ConfidenceScore": 0.6859999999999999,
            "FormattedTranscription": "ten to the at terminal two",
            "FixedTranscription": ""
          }
        ]
      }
    }
    */

    //Fires if error occurs during the request
    function onError(err, info) {
      statusElt.innerText = "Error: " + JSON.stringify(err);
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = false;
      infoElt.value = JSON.stringify(info, undefined, 2);
    }

    //Fires every time backend sends a speech-to-text
    //transcript of a voice query
    //See https://houndify.com/reference/HoundPartialTranscript
    function onTranscriptionUpdate(transcript) {
      transcriptElt.value = transcript.PartialTranscript;
    }
  </script>
{% endblock %}

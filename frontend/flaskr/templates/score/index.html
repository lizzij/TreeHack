{% extends 'base.html' %}

{% block header %}
<h1>{% block title %}{% endblock %}</h1>
<script src="https://unpkg.com/houndify@3.0.3/dist/houndify.js"></script>
<script src="https://unpkg.com/jquery@3.3.1/dist/jquery.js"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js@2.8.0"></script>
<!-- This is the houndify css-->
<link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.2.4/semantic.min.css"
/>
<script src="{{ url_for('static', filename='js_bootstrap/bootstrap.js') }}"></script>
<link rel="stylesheet" href="{{ url_for('static', filename='styles.css') }}">
<link rel="stylesheet" href="{{ url_for('static', filename='css_bootstrap/bootstrap.css') }}">

{% endblock %}

{% block content %}

<div class="row" style="margin: 20px">
  <div class="col-sm-2"
  style="padding: 10px; margin-left: 10px; margin-right: 10px;">
    <div class="row zoom"
    style="margin-top: 10px; margin-bottom: 10px; border-radius:5px;">
      <div class="tooltip tooltiptop"
      style="display:flex; justify-content:center; font-size: 1.4rem; padding:10px;"
      >
      The true phrase:
      </div>
    </div>
    <div class="row zoom"
    style="margin-top: 10px; margin-bottom: 10px; border-radius:5px;">
      <div class="tooltipbottom"
      style="display:flex; justify-content:center; font-size: 1.4rem; padding:10px"
      >
      What we heard:
      </div>
    </div>
  </div>
  {% for col in word_analysis %}
  <div class="col-sm-2"
  style="padding: 10px; margin-left: 10px; margin-right: 10px;">
    <div class="row zoom"
    style="background-color:{{ col["true_color"] }}; color:black; margin-top: 10px; margin-bottom: 10px; border-radius:5px;">
      <div class="tooltip tooltiptop"
      style="display:flex; justify-content:center; font-size: 1.4rem; padding:10px;"
      >
        {% if col["true_word"] != "" %}
          {{ col["true_word"] }}
        {% else %}
          <br>
        {% endif %}
        {% if col["true_issue"] != "" %}
          <span class="tooltiptext" style="z-index: 10;">{{col["true_issue"]}}</span>
        {% endif %}
      </div>
    </div>
    <div class="row zoom"
    style="background-color:{{ col["spoken_color"] }}; color:black; margin-top: 10px; margin-bottom: 10px; border-radius:5px;">
      <div class="tooltipbottom"
      style="display:flex; justify-content:center; font-size: 1.4rem; padding:10px"
      >
        {% if col["spoken_word"] != "" %}
          {{ col["spoken_word"] }}
        {% else %}
          <br>
        {% endif %}
        {% if col["spoken_issue"] != "" %}
        <span class="tooltiptextbottom" style="z-index: 10;">{{col["spoken_issue"]}}</span>
        {% endif %}
      </div>
    </div>
  </div>
  {% endfor %}
  </div>
  <div id="chartDiv"> 
    <canvas id="myChart" width="400" height="400" style="border:1px solid; height: 300px;">
  </div>
  <div id="chartDivConf"> 
    <canvas id="myChartConf" width="400" height="400" style="border:1px solid; height: 300px;">
  </div>
  <div id="conversationContainer">

    <div id="choicesContainer">
      <input class="choices" type="button" id="pracBut" value="Practice exercises" />
      <input class="choices" type="button" id="dyspraxiaBut" value="Tell me about dyspraxia" />
      <input class="choices" type="button" id="dysfluencyBut" value="Tell me about disfluency" />
    </div>

    <div class="speech-bubble-right" id="firstResponse" style="visibility:hidden; display: none"><p></p></div>
    <div class="speech-bubble-left" id="secondResponse" style="visibility:hidden; display: none"><p></p></div>

    <p id="definitionText" style="margin-bottom: 15px; display: none"></p>
  </div>

  <div id="voiceInputContainer">
    <div class="ui center aligned basic segment container">
    <form id="form" class="ui form" action="javascript:void(0);">
      <div class="ui action big labeled fluid input field">
        <div class="ui icon basic label button" onclick="onMicrophoneClick()">
          <i id="voiceIcon" class="unmute big icon"></i>
        </div>
        <input
          id="query"
          type="text"
          placeholder=""
        />
        <button
          id="textSearchButton"
          class="ui icon button"
          onclick="initTextRequest()"
        >
          <i class="search big icon"></i>
        </button>
      </div>

      <!-- <div class="ui field">
        <label class="ui label" for="file"
          >Or upload a recorded voice query from a file</label
        >
        <input type="file" id="file" name="file" onchange="onFileUpload()" />
      </div> -->

      <div id="status" class="ui info message">
        Click on microphone icon or type in the text query.
      </div>

      <div class="ui field" hidden>
        <label>Response object</label>
        <textarea id="responseJSON"></textarea>
      </div>
      <div class="ui field" hidden>
        <label>Search info object</label>
        <textarea id="infoJSON"></textarea>
      </div>
    </form>
  </div>
  <script>
    const word_analysis_data = JSON.parse('{{ word_analysis|tojson }}');
    const chart_data = [0, 0, 0, 0];
    console.log(word_analysis_data);
    const conf_data = [];
    const spoken_words = [];
    for (let idx = 0; idx < word_analysis_data.length; idx++) {
      if (word_analysis_data[idx]['spoken_word'].length > 0) {
        let split_words = word_analysis_data[idx]['spoken_word'].split(' ')
        for (let j = 0; j < split_words.length; j++) {
          if (split_words[j].length > 0) {
          conf_data.push(word_analysis_data[idx]['conf'])
          spoken_words.push(split_words[j])

          }
        }
      }
      
      if (word_analysis_data[idx]['spoken_issue'] === '') {
        chart_data[0] = chart_data[0] + 1;
      } else if (word_analysis_data[idx]['spoken_issue'] === 'omission') {
        chart_data[1] = chart_data[1] + 1;
      } else if (word_analysis_data[idx]['spoken_issue'] === 'dyspraxia') {
        chart_data[2] = chart_data[2] + 1;
      } else if (word_analysis_data[idx]['spoken_issue'] === 'stutter') {
        chart_data[3] = chart_data[3] + 1;
      }

      if (word_analysis_data[idx]['true_issue'] === '') {
        chart_data[0] = chart_data[0] + 1;
      } else if (word_analysis_data[idx]['true_issue'] === 'omission') {
        chart_data[1] = chart_data[1] + 1;
      } else if (word_analysis_data[idx]['true_issue'] === 'dyspraxia') {
        chart_data[2] = chart_data[2] + 1;
      } else if (word_analysis_data[idx]['true_issue'] === 'stutter') {
        chart_data[3] = chart_data[3] + 1;
      }
    }
    console.log(spoken_words);
    console.log(conf_data);
    var ctxConf = document.getElementById('myChartConf').getContext('2d');
    var myLineChart = new Chart(ctxConf, {
        type: 'line',
        data: {
        labels: spoken_words,
        datasets: [{
            label: 'My First dataset',
            backgroundColor: 'rgb(255, 99, 132)',
            borderColor: 'rgb(255, 99, 132)',
            data: conf_data
        }]
    },
        options: {
          maintainAspectRatio: false
        }
    });


    var ctx = document.getElementById('myChart').getContext('2d');
    document.getElementById('myChart').width = 400;
    console.log(document.getElementById('myChart').width);
    var myChart = new Chart(ctx, {
        type: 'bar',
        data: {
            labels: ['Correct', 'Omission', 'Dyspraxia', 'Stutter'],
            datasets: [{
                label: '# of Occurrences',
                data: chart_data,
                backgroundColor: [
                    'rgba(75, 192, 192, 0.2)',
                    'rgba(54, 162, 235, 0.2)',
                    'rgba(255, 206, 86, 0.2)',
                    'rgba(255, 99, 132, 0.2)',
                ],
                borderColor: [
                    'rgba(75, 192, 192, 1)',
                    'rgba(54, 162, 235, 1)',
                    'rgba(255, 206, 86, 1)',
                    'rgba(255, 99, 132, 1)',
                ],
                borderWidth: 1
            }]
        },
        options: {
            maintainAspectRatio: false,
            scales: {
                yAxes: [{
                    ticks: {
                        beginAtZero: true
                    }
                }]
            }
        }
    });
  </script>
  <script>
    function textToSpeech(phrase) {
      window.speechSynthesis.cancel();
      // list of languages is probably not loaded, wait for it
      if(window.speechSynthesis.getVoices().length == 0) {
        window.speechSynthesis.addEventListener('voiceschanged', function() {
          textToSpeechHelper(phrase);
        });
      }
      else {
        // languages list available, no need to wait
        textToSpeechHelper(phrase);
      }

    }

    function textToSpeechHelper(phrase) {
      // get all voices that browser offers
      var available_voices = window.speechSynthesis.getVoices();
      console.log(available_voices);
      // this will hold an english voice
      var english_voice = '';

      // find voice by language locale "en-US"
      // if not then select the first voice
      /* We want uk female!
      for(var i=0; i<available_voices.length; i++) {
        if(available_voices[i].lang === 'en-US') {
          english_voice = available_voices[i];
          break;
        }
      }
      */
     english_voice = available_voices[4];
      if(english_voice === '')
        english_voice = available_voices[0];

      // new SpeechSynthesisUtterance object
      var utter = new SpeechSynthesisUtterance();
      utter.rate = 0.75;
      utter.pitch = 1;
      utter.text = phrase;
      utter.voice = english_voice;

      // event after text has been spoken
      utter.onend = function() {
        console.log('Speech has finished');
        window.speechSynthesis.cancel()
      }

      // speak
      window.speechSynthesis.speak(utter);
    }
  </script>
	<script>
		var pracBut = document.getElementById("pracBut");
		pracBut.addEventListener("click", ToPrac);
		function ToPrac() {
			console.log("Prac");
			window.location.href='{{ url_for('practice.start_practice') }}';
		}
		var dyspraxiaBut = document.getElementById("dyspraxiaBut");
		dyspraxiaBut.addEventListener("click", ToDyspraxia);
		function ToDyspraxia() {
      console.log("Dyspraxia");
      document.getElementById("query").value = "Tell me about dyspraxia";
      initTextRequest();
      // Call the wikipedia speech to text
		}
		var dysfluencyBut = document.getElementById("dysfluencyBut");
		dysfluencyBut.addEventListener("click", ToDysfluency);
		function ToDysfluency() {
      console.log("Dysfluency");
      document.getElementById("query").value = "Tell me about dysfluency";
      initTextRequest();
      // Call the wikipedia speech to text
		}
	</script>
  <script>
    // Start of Houndify code
    //HTML ELEMENTS FOR DISPLAYING RESPONSE AND INFO JSON's
    var responseElt = document.getElementById("responseJSON");
    var infoElt = document.getElementById("infoJSON");
    var statusElt = document.getElementById("status");
    var transcriptElt = document.getElementById("query");
    var definitionText = document.getElementById("definitionText");

    var clientID = "6gG_SPtR_YNCOaTvI0IK5w==";
    var conversationState = {};
    var voiceRequest = null;

    var recorder = new Houndify.AudioRecorder();
    recorder.on("start", function() {
      //Initialize VoiceRequest
      voiceRequest = initVoiceRequest(recorder.sampleRate);
      document.getElementById("voiceIcon").className =
      "selected radio icon big red";
    });

    recorder.on("data", function(data) {
      voiceRequest.write(data);
    });

    recorder.on("end", function() {
      voiceRequest.end();
      statusElt.innerText = "Stopped recording. Waiting for response...";
      document.getElementById("voiceIcon").className = "unmute big icon";
      document.getElementById("textSearchButton").disabled = false;
      document.getElementById("query").readOnly = false;
    });

    recorder.on("error", function(error) {
      voiceRequest.abort();
      statusElt.innerText = "Error: " + error;
      document.getElementById("voiceIcon").className = "unmute big icon";
      document.getElementById("textSearchButton").disabled = false;
      document.getElementById("query").readOnly = false;
    });

    function initTextRequest() {
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = true;

      var queryString = document.getElementById("query").value;
      statusElt.innerText = "Sending text request...";
      fetch('/textSearchProxy?query=' + encodeURIComponent(queryString))
      .then(
        function(response) {
          if (response.status !== 200) {
            console.log('Looks like there was a problem. Status Code: ' +
              response.status);
            return;
          }
          // Examine the text in the response
          response.json().then(function(data) {
            console.log(data);
            onResponse(data, {});
          });
        }
      )
      .catch(function(err) {
        console.log('Fetch Error :-S', err);
        onError(data, {});
      });
      //Initialize TextRequest
      /*
      var textRequest = new Houndify.TextRequest({
        //Text query
        query: queryString,

        //Your Houndify Client ID
        clientId: clientID,

        //For testing environment you might want to authenticate on frontend without Node.js server.
        //In that case you may pass in your Houndify Client Key instead of "authURL".
        clientKey: "3lHbv1T8X5UDUa4tGhogToKa9iBIAMLdGK02zUq-ZwsBZ6BdaAElh42Z-nVnDoKfiu_3zCYxqrL4Ux2Iqs7X9A==",

        //Otherwise you need to create an endpoint on your server
        //for handling the authentication.
        //See SDK's server-side method HoundifyExpress.createAuthenticationHandler().
        //authURL: "/houndifyAuth",

        //REQUEST INFO JSON
        //See https://houndify.com/reference/RequestInfo
        requestInfo: {
          UserID: "test_user",
          Latitude: 37.388309,
          Longitude: -121.973968,
        },

        //Pass the current ConversationState stored from previous queries
        //See https://www.houndify.com/docs#conversation-state
        conversationState: conversationState,

        //You need to create an endpoint on your server
        //for handling the authentication and proxying
        //text search http requests to Houndify backend
        //See SDK's server-side method HoundifyExpress.createTextProxyHandler().
        proxy: {
          method: "POST",
          url: "/textSearchProxy",
          // headers: {}
          // ... More proxy options will be added as needed
        },

        //Response and error handlers
        onResponse: onResponse,
        onError: onError,
      });
      */
    }

    function initVoiceRequest(sampleRate) {
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = true;

      var voiceRequest = new Houndify.VoiceRequest({
      //Your Houndify Client ID
      clientId: clientID,
      clientKey: "3lHbv1T8X5UDUa4tGhogToKa9iBIAMLdGK02zUq-ZwsBZ6BdaAElh42Z-nVnDoKfiu_3zCYxqrL4Ux2Iqs7X9A==",
      //authURL: "/houndifyAuth",
      requestInfo: {
        UserID: "test_user",
        Latitude: 37.388309,
        Longitude: -121.973968,
      },
      conversationState,

      //Sample rate of input audio
      sampleRate,

      //Enable Voice Activity Detection
      //Default: true
      enableVAD: true,

      //Partial transcript, response and error handlers
      onTranscriptionUpdate: onTranscriptionUpdate,
      onResponse: function(response, info) {
        recorder.stop();
        onResponse(response, info);
      },
      onError: function(err, info) {
        recorder.stop();
        onError(err, info);
      },
      });

      return voiceRequest;
    }

    function onMicrophoneClick() {
      if (recorder && recorder.isRecording()) {
      recorder.stop();
      return;
      }

      recorder.start();

      statusElt.innerText = "Streaming voice request...";
      document.getElementById("voiceIcon").className =
      "loading circle notched icon big";
      document.getElementById("textSearchButton").disabled = true;
      document.getElementById("query").readOnly = true;
    }

    function onFileUpload() {
      var reader = new FileReader();
      reader.onload = function() {
      //In browsers only you can also upload and decode
      //audio file using decodeArrayBuffer() method
      //Stream 8/16 kHz mono 16-bit little-endian PCM samples
      //in Int16Array() chunks to backend
      var arrayBuffer = reader.result;
      Houndify.decodeAudioData(arrayBuffer, function(err, result) {
        statusElt.innerText = "Streaming audio from file...";
        voiceRequest = initVoiceRequest(result.sampleRate);
        voiceRequest.write(result.audioData);
        voiceRequest.end();
      });

      statusElt.innerText = "Decoding audio from file...";
      };

      var file = document.getElementById("file").files[0];
      reader.readAsArrayBuffer(file);
    }

    //Fires after server responds with Response JSON
    //Info object contains useful information about the completed request
    //See https://houndify.com/reference/HoundServer
    function onResponse(response, info) {
      if (response.AllResults && response.AllResults.length) {
      //Pick and store appropriate ConversationState from the results.
      //This example takes the default one from the first result.
      conversationState = response.AllResults[0].ConversationState;
      }

      statusElt.innerText = "Received response.";
      // responseElt.parentNode.hidden = false;
      // responseElt.value = JSON.stringify(response, undefined, 2);

      let commandType = response.AllResults[0].CommandKind;
      let action = (response.AllResults[0].Result || {}).action;

      console.log(action);
      var firstResponse = document.getElementById("firstResponse");
      firstResponse.style.visibility='visible';
      firstResponse.style.display='';
      var transcript = response.Disambiguation.ChoiceData[0].FormattedTranscription;
      console.log(transcript)
      firstResponse.innerText = transcript;

      var secondResponse = document.getElementById("secondResponse");

      console.log(commandType);
      if (commandType == "InformationCommand" ||
          commandType == "DictionaryCommand") {
        // show and say the spoken response
        let spokenResponse = response.AllResults[0].SpokenResponse;
        let writtenResponse = response.AllResults[0].WrittenResponseLong;
        definitionText.innerText = writtenResponse;
        textToSpeech(spokenResponse);
        secondResponse.style.visibility='visible';
        secondResponse.style.display='';
        secondResponse.innerText = writtenResponse;

      } else {
        if (action === undefined) {
          // errored
        } else if (action == "start_exercises") {

          // start face movement exercises
          console.log(action);
          secondResponse.style.visibility='visible';
          secondResponse.style.display='';
          secondResponse.innerText = "Alright, starting your exercises!";

          textToSpeech("Alright, starting your exercises!");
          setTimeout(function(){
            window.location.href='{{ url_for('practice.start_practice') }}';
          }, 3000);
          

        } else if (action == "restart_session") {

          console.log(action);
          secondResponse.style.visibility='visible';
          secondResponse.innerText = "Sounds good, let's do another session.";
          secondResponse.style.display='';
          textToSpeech("Sounds good, let's do another session.");
          setTimeout(function(){
            window.location.href='{{ url_for('record.index') }}';
          }, 3000);
        }
      }

      //infoElt.parentNode.hidden = false;
      //infoElt.value = JSON.stringify(info, undefined, 2);
    }

    /*
    // Example of success
    {
      "Format": "SoundHoundVoiceSearchResult",
      "FormatVersion": "1.0",
      "Status": "OK",
      "NumToReturn": 1,
      "AllResults": [
        {
          "CommandKind": "InformationCommand",
          "SpokenResponse": "A speech disfluency, also spelled speech dysfluency, is any of various breaks, irregularities , or non-lexical vocables that occurs within the flow of otherwise fluent speech.",
          "SpokenResponseLong": "A speech disfluency, also spelled speech dysfluency, is any of various breaks, irregularities , or non-lexical vocables that occurs within the flow of otherwise fluent speech.",
          "WrittenResponse": "Speech disfluency",
          "WrittenResponseLong": "A speech disfluency, also spelled speech dysfluency, is any of various breaks, irregularities (within the English language, similar speech dysfluency occurs in different forms in other languages), or non-lexical vocables that occurs within the flow of otherwise fluent speech.",
          "AutoListen": false
        }
      ]
    }
    // Example of failure
    {
      "Format": "SoundHoundVoiceSearchResult",
      "FormatVersion": "1.0",
      "Status": "OK",
      "NumToReturn": 1,
      "AllResults": [
        {
          "CommandKind": "NoResultCommand",
          "SpokenResponse": "",
          "SpokenResponseLong": "Didn't get that!",
          "WrittenResponse": "Didn't get that!",
          "WrittenResponseLong": "Didn't get that!",
          "AutoListen": false,
          "ViewType": [
            "Native",
            "None"
          ],
          "TranscriptionSearchURL": "http://www.google.com/#q=ten%20to%20the%20at%20terminal%20two"
        }
      ],
      "Disambiguation": {
        "NumToShow": 1,
        "ChoiceData": [
          {
            "Transcription": "ten to the at terminal two",
            "ConfidenceScore": 0.6859999999999999,
            "FormattedTranscription": "ten to the at terminal two",
            "FixedTranscription": ""
          }
        ]
      }
    }
    */

    //Fires if error occurs during the request
    function onError(err, info) {
      statusElt.innerText = "Error: " + JSON.stringify(err);
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = false;
      infoElt.value = JSON.stringify(info, undefined, 2);
    }

    //Fires every time backend sends a speech-to-text
    //transcript of a voice query
    //See https://houndify.com/reference/HoundPartialTranscript
    function onTranscriptionUpdate(transcript) {
      transcriptElt.value = transcript.PartialTranscript;
    }
  </script>
{% endblock %}

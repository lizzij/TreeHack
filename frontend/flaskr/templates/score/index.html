{% extends 'base.html' %}

{% block header %}
<h1>{% block title %}{% endblock %}</h1>
<script src="https://unpkg.com/houndify@3.0.3/dist/houndify.js"></script>
<script src="https://unpkg.com/jquery@3.3.1/dist/jquery.js"></script>
<!-- This is the houndify css-->
<link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.2.4/semantic.min.css"
/>
<script src="{{ url_for('static', filename='js_bootstrap/bootstrap.js') }}"></script>
<!-- <link rel="stylesheet" href="styles.css"> -->
<link rel="stylesheet" href="{{ url_for('static', filename='css_bootstrap/bootstrap.css') }}">

{% endblock %}

{% block content %}

  <div id="resultContainer">
    <div class="row" style="margin: 20px">
      {% for col in word_analysis %}
        <div class="col-sm-2"
        style="padding: 10px; margin-left: 10px; margin-right: 10px;">
          <div class="row zoom"
          style="background-color:{{ col["true_color"] }}; color:#FFF; margin-top: 10px; margin-bottom: 10px; border-radius:5px;">
            <div class="tooltip tooltiptop"
            style="display:flex; justify-content:center; font-size: 20px; padding:10px;"
            >
              {{ col["true_word"] }}
              {% if col["true_issue"] != "" %}
                <span class="tooltiptext">{{col["true_issue"]}}</span>
              {% endif %}
            </div>
          </div>
          <div class="row zoom"
          style="background-color:{{ col["pred_color"] }}; color:#FFF; margin-top: 10px; margin-bottom: 10px; border-radius:5px;">
            <div class="tooltipbottom"
            style="display:flex; justify-content:center; font-size: 20px; padding:10px"
            >
              {{ col["pred_word"] }}
              {% if col["pred_issue"] != ""%}
              <span class="tooltiptextbottom">{{col["pred_issue"]}}</span>
              {% endif %}
            </div>
          </div>
        </div>
      {% endfor %}
    </div>
  </div>

  <div id="conversationContainer">

    <div class="speech-bubble-left" ><p>Choose one:</p></div>

    <div id="choicesContainer">
      <input class="choices" type="button" id="pracBut" value="Practice" />
      <input class="choices" type="button" id="dyspraxiaBut" value="Tell me about dyspraxia" />
      <input class="choices" type="button" id="dysfluencyBut" value="Tell me about disfluency" />
    </div>

    <div class="speech-bubble-right" id="firstResponse" style="visibility:hidden;"><p></p></div>

    <p id="definitionText"></p>
  </div>

  <div id="voiceInputContainer">
    <div class="ui center aligned basic segment container">
    <form id="form" class="ui form" action="javascript:void(0);">
      <div class="ui action big labeled fluid input field">
        <div class="ui icon basic label button" onclick="onMicrophoneClick()">
          <i id="voiceIcon" class="unmute big icon"></i>
        </div>
        <input
          id="query"
          type="text"
          placeholder=""
        />
        <button
          id="textSearchButton"
          class="ui icon button"
          onclick="initTextRequest()"
        >
          <i class="search big icon"></i>
        </button>
      </div>

      <!-- <div class="ui field">
        <label class="ui label" for="file"
          >Or upload a recorded voice query from a file</label
        >
        <input type="file" id="file" name="file" onchange="onFileUpload()" />
      </div> -->

      <div id="status" class="ui info message">
        Click on microphone icon or type in the text query.
      </div>

      <div class="ui field" hidden>
        <label>Response object</label>
        <textarea id="responseJSON"></textarea>
      </div>
      <div class="ui field" hidden>
        <label>Search info object</label>
        <textarea id="infoJSON"></textarea>
      </div>
    </form>
  </div>
  </div>

  <script>
    function textToSpeech(phrase) {
      // list of languages is probably not loaded, wait for it
      if(window.speechSynthesis.getVoices().length == 0) {
        window.speechSynthesis.addEventListener('voiceschanged', function() {
          textToSpeechHelper(phrase);
        });
      }
      else {
        // languages list available, no need to wait
        textToSpeechHelper(phrase);
      }

    }

    function textToSpeechHelper(phrase) {
      // get all voices that browser offers
      var available_voices = window.speechSynthesis.getVoices();
      console.log(available_voices);
      // this will hold an english voice
      var english_voice = '';

      // find voice by language locale "en-US"
      // if not then select the first voice
      /* We want uk female!
      for(var i=0; i<available_voices.length; i++) {
        if(available_voices[i].lang === 'en-US') {
          english_voice = available_voices[i];
          break;
        }
      }
      */
     english_voice = available_voices[4];
      if(english_voice === '')
        english_voice = available_voices[0];

      // new SpeechSynthesisUtterance object
      var utter = new SpeechSynthesisUtterance();
      utter.rate = 1;
      utter.pitch = 1;
      utter.text = phrase;
      utter.voice = english_voice;

      // event after text has been spoken
      utter.onend = function() {
        console.log('Speech has finished');
        window.speechSynthesis.cancel()
      }

      // speak
      window.speechSynthesis.speak(utter);
    }
  </script>
	<script>
		var pracBut = document.getElementById("pracBut");
		pracBut.addEventListener("click", ToPrac);
		function ToPrac() {
			console.log("Prac");
			window.location.href='{{ url_for('practice.start_practice') }}';
		}
		var dyspraxiaBut = document.getElementById("dyspraxiaBut");
		dyspraxiaBut.addEventListener("click", ToDyspraxia);
		function ToDyspraxia() {
      console.log("Dyspraxia");
      document.getElementById("query").value = "Tell me about dyspraxia";
      initTextRequest();
      // Call the wikipedia speech to text
		}
		var dysfluencyBut = document.getElementById("dysfluencyBut");
		dysfluencyBut.addEventListener("click", ToDysfluency);
		function ToDysfluency() {
      console.log("Dysfluency");
      document.getElementById("query").value = "Tell me about dysfluency";
      initTextRequest();
      // Call the wikipedia speech to text
		}
	</script>
  <script>
    // Start of Houndify code
    //HTML ELEMENTS FOR DISPLAYING RESPONSE AND INFO JSON's
    var responseElt = document.getElementById("responseJSON");
    var infoElt = document.getElementById("infoJSON");
    var statusElt = document.getElementById("status");
    var transcriptElt = document.getElementById("query");
    var definitionText = document.getElementById("definitionText");

    var clientID = "6gG_SPtR_YNCOaTvI0IK5w==";
    var conversationState = {};
    var voiceRequest = null;

    var recorder = new Houndify.AudioRecorder();
    recorder.on("start", function() {
      //Initialize VoiceRequest
      voiceRequest = initVoiceRequest(recorder.sampleRate);
      document.getElementById("voiceIcon").className =
      "selected radio icon big red";
    });

    recorder.on("data", function(data) {
      voiceRequest.write(data);
    });

    recorder.on("end", function() {
      voiceRequest.end();
      statusElt.innerText = "Stopped recording. Waiting for response...";
      document.getElementById("voiceIcon").className = "unmute big icon";
      document.getElementById("textSearchButton").disabled = false;
      document.getElementById("query").readOnly = false;
    });

    recorder.on("error", function(error) {
      voiceRequest.abort();
      statusElt.innerText = "Error: " + error;
      document.getElementById("voiceIcon").className = "unmute big icon";
      document.getElementById("textSearchButton").disabled = false;
      document.getElementById("query").readOnly = false;
    });

    function initTextRequest() {
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = true;

      var queryString = document.getElementById("query").value;
      statusElt.innerText = "Sending text request...";
      fetch('/textSearchProxy?query=' + encodeURIComponent(queryString))
      .then(
        function(response) {
          if (response.status !== 200) {
            console.log('Looks like there was a problem. Status Code: ' +
              response.status);
            return;
          }
          // Examine the text in the response
          response.json().then(function(data) {
            console.log(data);
            onResponse(data, {});
          });
        }
      )
      .catch(function(err) {
        console.log('Fetch Error :-S', err);
        onResponse(data, {});
      });
      //Initialize TextRequest
      /*
      var textRequest = new Houndify.TextRequest({
        //Text query
        query: queryString,

        //Your Houndify Client ID
        clientId: clientID,

        //For testing environment you might want to authenticate on frontend without Node.js server.
        //In that case you may pass in your Houndify Client Key instead of "authURL".
        clientKey: "3lHbv1T8X5UDUa4tGhogToKa9iBIAMLdGK02zUq-ZwsBZ6BdaAElh42Z-nVnDoKfiu_3zCYxqrL4Ux2Iqs7X9A==",

        //Otherwise you need to create an endpoint on your server
        //for handling the authentication.
        //See SDK's server-side method HoundifyExpress.createAuthenticationHandler().
        //authURL: "/houndifyAuth",

        //REQUEST INFO JSON
        //See https://houndify.com/reference/RequestInfo
        requestInfo: {
          UserID: "test_user",
          Latitude: 37.388309,
          Longitude: -121.973968,
        },

        //Pass the current ConversationState stored from previous queries
        //See https://www.houndify.com/docs#conversation-state
        conversationState: conversationState,

        //You need to create an endpoint on your server
        //for handling the authentication and proxying
        //text search http requests to Houndify backend
        //See SDK's server-side method HoundifyExpress.createTextProxyHandler().
        proxy: {
          method: "POST",
          url: "/textSearchProxy",
          // headers: {}
          // ... More proxy options will be added as needed
        },

        //Response and error handlers
        onResponse: onResponse,
        onError: onError,
      });
      */
    }

    function initVoiceRequest(sampleRate) {
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = true;

      var voiceRequest = new Houndify.VoiceRequest({
      //Your Houndify Client ID
      clientId: clientID,
      clientKey: "3lHbv1T8X5UDUa4tGhogToKa9iBIAMLdGK02zUq-ZwsBZ6BdaAElh42Z-nVnDoKfiu_3zCYxqrL4Ux2Iqs7X9A==",
      //authURL: "/houndifyAuth",
      requestInfo: {
        UserID: "test_user",
        Latitude: 37.388309,
        Longitude: -121.973968,
      },
      conversationState,

      //Sample rate of input audio
      sampleRate,

      //Enable Voice Activity Detection
      //Default: true
      enableVAD: true,

      //Partial transcript, response and error handlers
      onTranscriptionUpdate: onTranscriptionUpdate,
      onResponse: function(response, info) {
        recorder.stop();
        onResponse(response, info);
      },
      onError: function(err, info) {
        recorder.stop();
        onError(err, info);
      },
      });

      return voiceRequest;
    }

    function onMicrophoneClick() {
      if (recorder && recorder.isRecording()) {
      recorder.stop();
      return;
      }

      recorder.start();

      statusElt.innerText = "Streaming voice request...";
      document.getElementById("voiceIcon").className =
      "loading circle notched icon big";
      document.getElementById("textSearchButton").disabled = true;
      document.getElementById("query").readOnly = true;
    }

    function onFileUpload() {
      var reader = new FileReader();
      reader.onload = function() {
      //In browsers only you can also upload and decode
      //audio file using decodeArrayBuffer() method
      //Stream 8/16 kHz mono 16-bit little-endian PCM samples
      //in Int16Array() chunks to backend
      var arrayBuffer = reader.result;
      Houndify.decodeAudioData(arrayBuffer, function(err, result) {
        statusElt.innerText = "Streaming audio from file...";
        voiceRequest = initVoiceRequest(result.sampleRate);
        voiceRequest.write(result.audioData);
        voiceRequest.end();
      });

      statusElt.innerText = "Decoding audio from file...";
      };

      var file = document.getElementById("file").files[0];
      reader.readAsArrayBuffer(file);
    }

    //Fires after server responds with Response JSON
    //Info object contains useful information about the completed request
    //See https://houndify.com/reference/HoundServer
    function onResponse(response, info) {
      if (response.AllResults && response.AllResults.length) {
      //Pick and store appropriate ConversationState from the results.
      //This example takes the default one from the first result.
      conversationState = response.AllResults[0].ConversationState;
      }

      statusElt.innerText = "Received response.";
      responseElt.parentNode.hidden = false;
      responseElt.value = JSON.stringify(response, undefined, 2);

      let commandType = response.AllResults[0].CommandKind;
      console.log(commandType);
      if (commandType == "InformationCommand" ||
          commandType == "DictionaryCommand") {
        // show and say the spoken response
        let spokenResponse = response.AllResults[0].SpokenResponse;
        let writtenResponse = response.AllResults[0].WrittenResponseLong;
        definitionText.innerText = writtenResponse;
        textToSpeech(spokenResponse);
      }

			// window.location.href='{{ url_for('score.display_score') }}';

      //infoElt.parentNode.hidden = false;
      //infoElt.value = JSON.stringify(info, undefined, 2);
    }

    /*
    // Example of success
    {
      "Format": "SoundHoundVoiceSearchResult",
      "FormatVersion": "1.0",
      "Status": "OK",
      "NumToReturn": 1,
      "AllResults": [
        {
          "CommandKind": "InformationCommand",
          "SpokenResponse": "A speech disfluency, also spelled speech dysfluency, is any of various breaks, irregularities , or non-lexical vocables that occurs within the flow of otherwise fluent speech.",
          "SpokenResponseLong": "A speech disfluency, also spelled speech dysfluency, is any of various breaks, irregularities , or non-lexical vocables that occurs within the flow of otherwise fluent speech.",
          "WrittenResponse": "Speech disfluency",
          "WrittenResponseLong": "A speech disfluency, also spelled speech dysfluency, is any of various breaks, irregularities (within the English language, similar speech dysfluency occurs in different forms in other languages), or non-lexical vocables that occurs within the flow of otherwise fluent speech.",
          "AutoListen": false
        }
      ]
    }
    // Example of failure
    {
      "Format": "SoundHoundVoiceSearchResult",
      "FormatVersion": "1.0",
      "Status": "OK",
      "NumToReturn": 1,
      "AllResults": [
        {
          "CommandKind": "NoResultCommand",
          "SpokenResponse": "",
          "SpokenResponseLong": "Didn't get that!",
          "WrittenResponse": "Didn't get that!",
          "WrittenResponseLong": "Didn't get that!",
          "AutoListen": false,
          "ViewType": [
            "Native",
            "None"
          ],
          "TranscriptionSearchURL": "http://www.google.com/#q=ten%20to%20the%20at%20terminal%20two"
        }
      ],
      "Disambiguation": {
        "NumToShow": 1,
        "ChoiceData": [
          {
            "Transcription": "ten to the at terminal two",
            "ConfidenceScore": 0.6859999999999999,
            "FormattedTranscription": "ten to the at terminal two",
            "FixedTranscription": ""
          }
        ]
      }
    }
    */

    //Fires if error occurs during the request
    function onError(err, info) {
      statusElt.innerText = "Error: " + JSON.stringify(err);
      responseElt.parentNode.hidden = true;
      infoElt.parentNode.hidden = false;
      infoElt.value = JSON.stringify(info, undefined, 2);
    }

    //Fires every time backend sends a speech-to-text
    //transcript of a voice query
    //See https://houndify.com/reference/HoundPartialTranscript
    function onTranscriptionUpdate(transcript) {
      transcriptElt.value = transcript.PartialTranscript;
    }
  </script>
{% endblock %}
